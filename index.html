<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }

  /* added by yc */

  padding {
    padding: 50px 0px;
  }

  </style>
  <link rel="icon" type="image/png" href="images/ucb.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Sangryul Jeon</title>
  <meta name="Sangryul Jeon's Homepage" http-equiv="Content-Type" content="Sangryul Jeon's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-64069893-1', 'auto');
    ga('send', 'pageview');
  </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<!-- <table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20"> -->
<table width="960" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <!-- <font size="7">Yen-Chi Cheng</font><br> -->
    <pageheading>Sangryul Jeon</pageheading><br>
    <!-- <b>email</b>: charlescheng0117_at_gmail_dot_com -->
    <!-- <b>email</b>: yenchicheng_at_cmu.edu -->
    <!-- <b>email</b>: yenchich_at_andrew.cmu.edu -->
    <!-- <b>email</b>: yenchich_at_cs.cmu.edu -->
    <b>email</b>: srjeon _at_ berkeley.edu
    <font id="email" style="display:inline;">
      <noscript><i>Please enable Javascript to view</i></noscript>
    </font>
    <!-- <script>
    emailScramble = new scrambledString(document.getElementById('email'),
        'emailScramble', '1cm0asg17eccmilnrlah.oge@h',
        [14, 8, 19, 13, 20, 7, 12, 15, 16, 6, 1, 24, 26, 21, 5, 11, 4, 22, 3, 9, 23, 25, 18, 10, 17, 2]);
        // 'emailScramble', 'charlescheng0117@gmail.com',
        // [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]);
    </script> -->
  </p>

  <tr>
    <!-- <td width="32%" valign="top"><a href="images/yenchicheng.png"><img src="images/yenchicheng.png" width="100%" style="border-radius:15px"></a> -->
    <td width="30%" valign="top"><a href="bww_22aug.jpg"><img src="bww_22aug.jpg" width="100%" style="border-radius:15px"></a>
        <p align=center>
          | <a href="https://drive.google.com/file/d/1Hm9-25a-wLDyfM5hiXU7wuXfCO5SIqDT/view?usp=sharing">CV</a> |
          <a href="https://scholar.google.com/citations?user=3s4zIroAAAAJ&hl=en">Google Scholar</a> |
          <a href="https://www.linkedin.com/in/sangryul-jeon-3b697b17a/">LinkedIn</a> |
      </p>
    </td>

    <td width="66%" valign="top" align="justify">
        <p>
        I am currently a postdoctoral scholar in Electrical Engineering and Computer Science
	at <a href="https://eecs.berkeley.edu/">University of California, Berkeley</a>, working in <a href="https://www.icsi.berkeley.edu/icsi/">International Computer Science Institute</a>
	advised by <a href="https://www1.icsi.berkeley.edu/~stellayu/">Prof. Stella X. Yu.</a>
        <br>
        <br>
        I obtained my B.S., and Ph.D. degrees advised by <a href="https://diml.yonsei.ac.kr/">Prof. Kwanghoon Sohn</a>
        in School of Electrical and Electronic Engineering from <a href="https://ee.yonsei.ac.kr/ee/index.do">Yonsei University</a> in 2016 and 2022, respectively.
        I was a research intern with researchers <a href="https://research.adobe.com/person/zhifei-zhang/">Zhifei Zhang</a> and <a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a>
        in Creative Intelligence Lab of <a href="https://research.adobe.com/">Adobe Research</a> from June 2021 to November 2021.
        <br>
        <br>
        My current research centers on analyzing local environments of an object or scene of interest without the need of supervision but driven by visual correspondences.
        </p>

        </td>
  </tr>
</table>

<!-- =================== Experience =================== -->
<table width="100%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
    <tr>
        <th width="20.75%" valign="top" align="center">
        <img src="images/ucb.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">UC Berkeley<br>Postdoctral scholar<br>Mar. 22 - Present</p>
        </th>

        <th width="20.75%" valign="top" align="center">
        <img src="images/icsi.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">ICSI<br>Postdoctoral researcher<br>Mar. 22 - Present</p>
        </th>

        <th width="20.75%" valign="top" align="center">
        <img src="images/adobe.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">Adobe research<br>Research intern<br>May. 21 - Nov. 21</p>
        </th>

        <th width="20.75%" valign="top" align="center">
          <img src="images/yonsei.jpeg" alt="sym" width="54%"></a>
          <p style="line-height:1.3; font-size:12pt">Yonsei university<br>
            Doctor of philosophy<br>Mar. 16 - Feb. 22</p>
        </th>
    </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="8">
  <tr><td>
    <sectionheading>&nbsp;&nbsp;News</sectionheading>
    <ul>
      <li> [10/2022] One paper accepted by <b>BMVC'22</b></li>
      <li> [09/2022] One paper accepted by <b>NeurIPS'22</b></li>
      <li> [03/2022] Joined <b>UC Berkeley / ICSI</b> as a postdoctoral scholar</li>
    </ul>
  </td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
<tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">


    <tr>
      <td width="33%" valign="top" align="center">
          <a href="#">
          <img src="images/bmvc22.png" alt="sym" width="300" height="240" style="border-radius:15px">
          </a>
      </td>

      <td width="67%" valign="top">
          <p>
              <a href="#" id="bmvc22">

              <heading>COAT: Correspondence-driven Object Appearance Transfer</heading></a>
              <br>
              <u><b>Sangryul Jeon</b></u>, Zhifei Zhang, Zhe Lin, Scott Cohen, Zhihong Ding, Kwanghoon Sohn
              <br>
              <!-- Under review -->
              BMVC 2022
          </p>

          <div class="paper" id="bmvc22">
          <a href="javascript:toggleblock('bmvc22_abs')">abstract</a> |

          <p align="justify">
              <i id="bmvc22_abs">
                Semantic correspondence is playing an increasingly important role in photorealistic style transfer, especially on objects with prior structural patterns like faces and cars. Unlike traditional methods that are blind to object/non-object regions and spatial correspondence between objects, we propose a new model called correspondence-driven object appearance transfer (COAT), which leverages correspondence to spatially align texture features to content features at multiple scales. Our model does not require extra supervision like semantic segmentation or body parsing and can be adapted to any given generic object category. More importantly, our multi-scale strategy achieves richer texture transfer, while at the same time preserving the spatial structure of objects in the content image. We further propose the correspondence contrastive loss (CCL) with hard negative mining during the training, boosting appearance transfer with improved disentanglement of structural and textural features. Exhaustive experimental evaluation on various objects demonstrates our superior robustness and visual quality as compared to state-of-the-art works.
              </i>
          </p>

          </div>
      </td>
    </tr>

    <tr>
      <td width="33%" valign="top" align="center">
          <a href="#">
          <img src="images/neurips22.png" alt="sym" width="300" height="200" style="border-radius:15px">
          </a>
      </td>

      <td width="67%" valign="top">
          <p>
              <a href="#" id="neurips22">

              <heading>Neural Matching Fields: Implicit Representation of Matching Fields for Visual Correspondence</heading></a>
              <br>
              Sunghwan Hong, Jisu Nam, Seokju Cho, Susung Hong, <u><b>Sangryul Jeon</b></u>, Dongbo Min, Seungryong Kim
              <br>
              <!-- Under review -->
              NeurIPS 2022
          </p>

          <div class="paper" id="neurips22">
          <a href="javascript:toggleblock('neurips22_abs')">abstract</a> |

          <p align="justify">
              <i id="neurips22_abs">
                Existing pipelines of semantic correspondence commonly include extracting high-level semantic features for the invariance against intra-class variations and background clutters. This architecture, however, inevitably results in a low-resolution matching field that additionally requires an ad-hoc interpolation process as a post-processing for converting it into a high-resolution one, certainly limiting the overall performance of matching results. To overcome this, inspired by recent success of implicit neural representation, we present a novel method for semantic correspondence, called neural matching field (NeMF). However, complicacy and high-dimensionality of a 4D matching field are the major hindrances, which we propose a cost embedding network to process a coarse cost volume to use as a guidance for establishing high-precision matching field through the following fully-connected network. Nevertheless, learning a high-dimensional matching field remains challenging mainly due to computational complexity, since a naive exhaustive inference would require querying from all pixels in the 4D space to infer pixel-wise correspondences. To overcome this, we propose adequate training and inference procedures, which in the training phase, we randomly sample matching candidates and in the inference phase, we iteratively performs PatchMatch-based inference and coordinate optimization at test time. With these combined, competitive results are attained on several standard benchmarks for semantic correspondence.
              </i>
          </p>

          </div>
      </td>
    </tr>



    <script xml:space="preserve" language="JavaScript">
    hideallbibs();
    </script>

    <script xml:space="preserve" language="JavaScript">
      hideblock('bmvc22_abs');
    </script>

    <script xml:space="preserve" language="JavaScript">
      hideblock('neurips22_abs');
    </script>

</body>

</html>
